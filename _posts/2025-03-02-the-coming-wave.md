---
layout: post
title: The Dilemma of Progress
date: 2025-03-03 06:00:00
description: Thoughts on the book - The Coming Wave
tags: ai
categories: book-reviews
thumbnail: assets/img/2025-02-03_the_coming_wave/the_coming_wave_book.jpeg
---

<p align="center">
    <img src="assets/img/2025-02-03_the_coming_wave/the_coming_wave_book.jpeg" alt="The Coming Wave">
    <br>
    <em><a href="https://a.co/d/4Qwlzob">The Coming Wave by Mustafa Suleyman and Michael Bhaskar</a></em>
</p>

I recently finished **The Coming Wave** by Mustafa Suleyman and Michael Bhaskar, and I’d like to share some of my thoughts, particularly on the topic of AI. The book explores the four transformative forces of the coming wave: **Artificial Intelligence, Synthetic Biology, Quantum Computing**, and emerging energy sources like **Nuclear Fusion**. AI and quantum computing are dominating the conversation these days, with new LLM models being launched almost weekly and major tech giants like Amazon, Microsoft, and Google unveiling groundbreaking research in quantum computing.

So far, we’ve experienced 24 major waves of innovation. Over a span of 10,000 years up until 1000 BCE, 7 general-purpose technologies emerged. Between 1700 and 1900, there were 6 waves, ranging from the steam engine to electricity. In the past 100 years alone, we’ve seen 7 new waves, from airplanes to nuclear power.

### The characteristics of the coming wave technologies

1. **New technology has a potential to scale assymetrically.**

- 1 Tweet -> Can spread an idea globally in an instant.
- 1 Startup -> Just one breakthrough algorithm can build a massive global company.
- 1 AI code -> Has the potential to write more code than all of humanity combined.
- 1 Bio experiment -> Could unleash a new pathogen, sparking a pandemic.
- 1 Viable quantum computer -> Has the power to render all encryption protocols obsolete.

2. **Hyper Evolution**
   These technologies are evolving rapidly and its difficult to contain these and their impact is global.

3. **Omni Use**
   These technologies have a broad spectrum of use cases, regardless of their original intentions and overtime the uses tend towards generality.

<!-- <p align=center>
<img src="../assets/img/2025-02-03_the_coming_wave/Use%20case%20spectrum.png" alt="Use case spectrum">
<br>
</img>
</p> -->

4. **Autonomy**
   Every iteration of these technologies make them more autonomous.

### Unstoppable incentives

There are unstoppable incentives to continue on the development of these technologies. Lets take the example of AI.

#### 1. Geopolitics

Nation states need to innovovate if they want to stay on top. AI has become a pivotal factor in global geopolitics, influencing economic strategies, national security policies, and international relations. Major powers like the United States, China, the European Union (EU), and emerging players such as India are heavily investing in AI to secure technological leadership and economic growth. The [Stargate Project](https://techcrunch.com/2025/01/21/openai-teams-up-with-softbank-and-oracle-on-50b-data-center-project/), a joint venture between OpenAI, Oracle, SoftBank, and other tech companies, with support from the US government plans to invest up to $500 billion over the next 4 years. Not just nation states, BigTech companies also need to innovate to stay on top and they have plan to spend more than $300 billion in 2025 on AI technologies and datacenter solutions. Not to be outdone by US and China, [EU has plans to invest ](https://www.wsj.com/tech/ai/eu-pledges-200-billion-in-ai-spending-in-bid-to-catch-up-with-u-s-china-7bf82ab5) 200 billion euros and India has plans [to invest $1.25 billion](https://www.reuters.com/technology/india-announces-12-bln-investment-ai-projects-2024-03-07/) to develop computing infrastructure and for the development of large language models.

#### 2. Open source research

Meta has been the leading force in open-source AI, with their Llama models driving research and innovation. However, the landscape is shifting. Deepseek-AI's recent emergence has shaken the AI world, triggering significant market volatility, including a [dramatic decline in Nvidia's market capitalization](https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/). The findings from Deepseek-AI's DeepSeek-R1 release and accompanying [methodology](https://arxiv.org/abs/2501.12948) are undoubtedly being explored by leading AI companies.

#### 3. Financial gains

Pinpointing the exact economic gains from AI is inherently difficult. However, a conservative projection by [MIT Professor Daron Acemoglu indicates a possible 1% growth in US GDP within the next decade](https://mitsloan.mit.edu/ideas-made-to-matter/a-new-look-economics-ai).

#### 4. Ego

The biggest example, that we are seeing play out in front of us the rivalry between Elon Musk and Sam Altman. Their feud stems from Musk’s belief that OpenAI betrayed its original mission by prioritizing profit and aligning too closely with Microsoft.
With **Musk backing xAI** and **Altman leading OpenAI**, the competition between their respective companies could push for:

- Faster AI advancements as each side competes to develop more powerful models.
- Diverging AI philosophies—Musk advocates for **"AI safety first"**, while Altman pushes for **"rapid innovation with safeguards"**.

## My thoughts on AI

### Current progress

Evolution, a process of iterative refinement, ultimately led to humanity. Imagine it as nature testing countless variations, culminating in us. While our evolution continues, it's now a slow crawl. The impact? Profound. Human intelligence has enabled us to manipulate natural resources and translate knowledge into powerful applications, dramatically reshaping our environment. This transformation, initially gradual, has accelerated exponentially in recent decades.

The pursuit of Artificial General Intelligence (AGI) mirrors evolution's iterative process, with numerous models being explored. While the precise impact of AGI remains uncertain, its potential magnitude, whether positive or negative, is unprecedented. Although timelines are debated, achieving something akin to AGI within the next few decades appears increasingly likely. Despite claims by some, like Sam Altman, current Large Language Models (LLMs) still lack the robust reasoning necessary for genuine world understanding.

The gap between claims of approaching AGI and the demonstrable limitations of current LLMs is evident in examples like their [inability to accurately count letters](https://www.reddit.com/r/OpenAI/comments/1haxhjk/can_someone_explain_exactly_why_llms_fail_at/) or [perform basic number comparisons](https://www.reddit.com/r/singularity/comments/1e4fcxm/none_of_current_llms_can_truly_reason_and_cannot/).
Even the GOAT, Karpathy, highlights these limitations in his latest YouTube video - [Deep Dive into LLMs like ChatGPT](https:/www.youtube.com/watch?v=7xTGNNLPyMI&t=7271s).

<!-- <p align=center>
<img src="../assets/img/2025-02-03_the_coming_wave/strawberry_fail.png" alt="The Coming Wave">
    <br>
    <em>Even latest models such as Gemini 2.0 fail</em>
</img>
</p> -->

I feel that companies are incentivized to say AGI is here or close to raise funding or to justify the billions of $ spent in capital expenditure as they chase bigger and bigger models.

### My worries about AI

If AI enables us to accomplish more with significantly less effort, the traditional need for large teams supporting a project may diminish. This shift raises a crucial question: will this efficiency lead to widespread unemployment, or will it instead fuel an explosion of new software products and innovations?

AI's ability to perform tasks previously handled by professionals also prompts an unsettling concern: what happens to the value of human knowledge? As AI can replicate—and in many cases, surpass—human skills, how can individuals ensure they remain indispensable? The challenge now goes beyond simply learning AI; it’s about positioning oneself to work alongside it rather than being replaced by it.

Many economists argue that as technology replaces existing jobs, new ones will be created. But in the age of AI, as it continuously learns and improves, it may eventually take over these new roles as well. This raises an important issue: will the new jobs created by AI be enough to absorb the millions displaced? Not everyone will have the skills or resources to transition into these new roles.

While jobs in the physical domain—such as cooks, masseuses, or other hands-on roles—may remain safer from automation, the real question is how many jobs in the information domain will remain immune to AI’s reach. As AI permeates more industries, it could make even information-based professions increasingly redundant, challenging our traditional understanding of work and human contribution.

The future workforce may not just involve humans augmenting AI; it could very well involve humans finding new ways to coexist with machines in a landscape where the value of human labor is rapidly evolving. And so the real question isn’t just about job displacement—it’s about redefining work itself. **Will the future workforce consist of humans augmenting AI, or will AI make human contribution increasingly redundant?**

### Genetic Engineering vs Software Engineering

The risks associated with genetic engineering are significantly higher than those in software engineering, primarily because biology operates in the real world, where unintended consequences can have profound and irreversible effects. A single mistake in genetic manipulation could lead to unforeseen mutations, ecological disruptions, or even biosecurity threats. As more individuals experiment with biohacking, the risks compound, making biological tinkering a potential global concern.

Software engineering, on the other hand, primarily exists in the digital realm, where errors—though sometimes costly—are generally more contained. Bugs in code can be patched, systems can be rebooted, and security vulnerabilities can be mitigated. However, the rise of artificial intelligence changes this equation. AI-driven applications now have the power to influence financial markets, critical infrastructure, healthcare decisions, and even warfare. While traditional software errors might not directly impact human biology, AI-enhanced software can blur the line between digital and physical consequences, making certain failures just as dangerous as biological mishaps.

One of the most striking developments in genetic AI is [Evo2](https://arcinstitute.org/news/blog/evo2), the latest LLM trained on **9.3 billion DNA sequences**. What makes Evo2 particularly alarming is its **open-source nature**, granting anyone—regardless of expertise—access to powerful genetic editing capabilities. In theory, this means that individuals with minimal formal training could modify DNA sequences from their own homes, synthesizing genetic changes in makeshift laboratories. The implications of such unrestricted access are vast, ranging from groundbreaking medical advancements to the potential for bioengineered pathogens.

As AI continues to integrate into both software and genetic engineering, the line between these fields is becoming increasingly blurred. The real question is: **Are we prepared for the consequences of democratizing such powerful technologies?**

## The Containment Plan

Suleyman's **containment plan for the coming wave of technological challenges** offers a thorough, multi-faceted strategy for managing potentially disruptive technologies such as AI and biotechnology. This is a highly complex subject that warrants a dedicated post of its own. This is in itself a very complex topic that deserves a separate post on its own. For now, the visual below offers a broad overview of the key elements of the containment plan, which will be explored in greater detail later.

<!-- <p align=center>
<img src="../assets/img/2025-02-03_the_coming_wave/The%20Containment%20Plan.png" alt="Containment plan">
<br>
</img>
</p> -->

Ultimately, **The Coming Wave** paints a stark, yet vital, picture of the technological future we're hurtling towards. As Mustafa Suleyman argues, the characteristics of these powerful technologies, coupled with the relentless incentives driving their development, particularly evident in the rapid evolution of AI, present us with unprecedented challenges. While the potential benefits are undeniable, the risks—the erosion of control, the potential for misuse, and the sheer scale of societal disruption—cannot be ignored. **The Containment Plan** offers a framework for navigating this turbulent landscape, but its success hinges on a collective commitment to proactive governance, ethical development, and a fundamental shift in how we perceive and manage technological progress. **Frankly, given the current geopolitical climate and the disparate motivations of those driving technological advancement, this level of unified, proactive action feels like a monumental, perhaps even impossible, undertaking**. Yet, the wave is coming, and whether it washes over us or carries us forward depends entirely on the choices we make today. The conversation, and more importantly, the action, must begin now.

### References

- Suleyman, M., & Bhaskar, M. (2023). _The Coming Wave: Technology, Power, and the Twenty-first Century's Greatest Dilemma_. Crown.

- [OpenAI teams up with SoftBank and Oracle on $50B data center project](https://techcrunch.com/2025/01/21/openai-teams-up-with-softbank-and-oracle-on-50b-data-center-project/)
- [EU Pledges $200 Billion in AI Spending in Bid to Catch Up With U.S., China](https://www.wsj.com/tech/ai/eu-pledges-200-billion-in-ai-spending-in-bid-to-catch-up-with-u-s-china-7bf82ab5)
- [India announces $12 bln investment in AI projects](https://www.reuters.com/technology/india-announces-12-bln-investment-ai-projects-2024-03-07/)
- [China's DeepSeek sets off AI market rout](https://www.reuters.com/technology/chinas-deepseek-sets-off-ai-market-rout-2025-01-27/)
- [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
- [A New Look at the Economics of AI](https://mitsloan.mit.edu/ideas-made-to-matter/a-new-look-economics-ai)
- [Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=7271s)
- [EVO2](https://arcinstitute.org/news/blog/evo2)
